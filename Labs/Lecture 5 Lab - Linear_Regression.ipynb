{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression and the Least Squares Method\n",
        "\n",
        "Linear regression is a fundamental technique in statistics and machine learning for modeling the relationship between a dependent variable $ y $ and one or more independent variables $ X $.\n",
        "\n",
        "In this lab, we will:\n",
        "\n",
        "1. Start with a simple linear regression example using real-world data.\n",
        "2. Express the least squares method using matrix notation.\n",
        "3. Perform multiple linear regression using built-in functions and matrix methods.\n",
        "4. Explore what happens when the data matrix is not full rank and the least squares method becomes unstable.\n"
      ],
      "metadata": {
        "id": "_crNVT5WrhNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Linear Regression with Real-World Data\n",
        "\n",
        "We'll use the California Housing Prices dataset to predict house prices based on a single feature: the median income in the neighborhood.\n",
        "\n",
        "The relationship between house price $( y )$ and median income $( X )$ is assumed to be linear:\n",
        "\n",
        "$$\n",
        "y = \\beta_0 + \\beta_1 X + \\epsilon\n",
        "$$\n",
        "\n",
        "Our goal is to estimate the parameters $ \\beta_0 $ (the intercept) and $ \\beta_1 $ (the slope) using the least squares method. The symbol $\\epsilon$ represents some random error.\n"
      ],
      "metadata": {
        "id": "iuSzTiiVrntL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBQeZGpkreZy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "housing = fetch_california_housing()\n",
        "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df['MedHouseVal'] = housing.target\n",
        "\n",
        "# Filter out the observations where MedHouseVal == 5\n",
        "df = df[df['MedHouseVal'] < 5]\n",
        "\n",
        "# Select a random subset of the data (e.g., 1000 samples)\n",
        "df_sample = df.sample(n=1000, random_state=42)\n",
        "\n",
        "# Use only the median income as the predictor\n",
        "X = df_sample[['MedInc']].values\n",
        "y = df_sample['MedHouseVal'].values\n",
        "\n",
        "# Plot the data\n",
        "plt.scatter(X, y, alpha=0.5)\n",
        "plt.title(\"House Prices vs Median Income (Filtered Subset)\")\n",
        "plt.xlabel(\"Median Income (in $10,000s)\")\n",
        "plt.ylabel(\"Median House Value (in $100,000s)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Least Squares Estimation\n",
        "\n",
        "The least squares method aims to minimize the sum of the squared differences between the observed values $ y_i $ and the predicted values $ \\hat{y_i}= \\beta_0 + \\beta_1 X_i$:\n",
        "\n",
        "$$\n",
        "\\min_{\\beta_0, \\beta_1} \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 X_i))^2\n",
        "$$\n",
        "\n",
        "Let's fit a simple linear regression model using the least squares method.\n"
      ],
      "metadata": {
        "id": "6hQiyWONsbSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the linear regression model\n",
        "reg = LinearRegression()\n",
        "reg.fit(X, y)\n",
        "\n",
        "# Plot the regression line and the errors\n",
        "plt.scatter(X, y, alpha=0.5)\n",
        "plt.plot(X, reg.predict(X), color='red', label=\"Regression Line\")\n",
        "plt.title(\"Linear Regression Fit\")\n",
        "plt.xlabel(\"Median Income (in $10,000s)\")\n",
        "plt.ylabel(\"Median House Value (in $100,000s)\")\n",
        "\n",
        "# Plot the errors (vertical lines)\n",
        "for i in range(len(X)):\n",
        "    plt.plot([X[i], X[i]], [y[i], reg.predict(X)[i]], color='gray', alpha=0.5)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Display the coefficients\n",
        "print(f\"Intercept (β0): {reg.intercept_:.2f}\")\n",
        "print(f\"Coefficient (β1): {reg.coef_[0]:.2f}\")\n"
      ],
      "metadata": {
        "id": "qiqZueVPsogo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Formulation of Linear Regression\n",
        "\n",
        "In matrix form, the linear regression model can be written as:\n",
        "\n",
        "$$\n",
        "y = X\\beta + \\epsilon\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $ y $ is the vector of observed values (in our case, the median house values).\n",
        "- $ X $ is the design matrix, where each row corresponds to an observation, and each column corresponds to a predictor (including the intercept term).\n",
        "- $ \\beta $ is the vector of coefficients (including the intercept).\n",
        "- $ \\epsilon $ is the vector of errors.\n",
        "\n",
        "### Understanding the Design Matrix $ X $\n",
        "\n",
        "For a simple linear regression with one predictor (e.g., median income), the design matrix $ X $ consists of:\n",
        "- A column of ones to account for the intercept term.\n",
        "- A column representing the values of the predictor variable (in this case, median income).\n",
        "\n",
        "Mathematically, for the first few observations, the design matrix $ X $ looks like this:\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "1 & X_1 \\\\\n",
        "1 & X_2 \\\\\n",
        "1 & X_3 \\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "1 & X_n \\\\\n",
        "\\end{pmatrix}\n",
        "= \\begin{pmatrix}\n",
        "1 & \\text{MedInc}_1 \\\\\n",
        "1 & \\text{MedInc}_2 \\\\\n",
        "1 & \\text{MedInc}_3 \\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "1 & \\text{MedInc}_n \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- The first column is all ones (corresponding to the intercept $ \\beta_0 $).\n",
        "- The second column consists of the values of the predictor variable (median income for each observation).\n",
        "\n",
        "\n",
        "The least squares estimate of $ \\beta $ is given by:\n",
        "\n",
        "$$\n",
        "\\hat{\\beta} = (X^TX)^{-1}X^Ty\n",
        "$$\n",
        "\n",
        "Let's compute this for our simple regression example.\n"
      ],
      "metadata": {
        "id": "eCDJF1GetXgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Add a column of ones to X for the intercept term\n",
        "X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "\n",
        "# Display the first few rows of the matrix X\n",
        "print(\"First few rows of the design matrix X:\")\n",
        "print(X_b[:5])\n",
        "\n",
        "# Compute the least squares solution using the formula\n",
        "beta_hat = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "\n",
        "print(f\"Computed intercept (β0): {beta_hat[0]:.2f}\")\n",
        "print(f\"Computed coefficient (β1): {beta_hat[1]:.2f}\")\n"
      ],
      "metadata": {
        "id": "83MT8tUruRNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Linear Regression\n",
        "\n",
        "Now let's extend our example to multiple linear regression, where we have multiple predictor variables. The model can still be written as:\n",
        "\n",
        "$$\n",
        "y = X\\beta + \\epsilon\n",
        "$$\n",
        "\n",
        "We'll use additional features from the California Housing dataset (e.g., average rooms per dwelling, population, median income) to predict house prices.\n"
      ],
      "metadata": {
        "id": "N_D8vK7quhLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use multiple features to predict house prices\n",
        "X_multi = df[['MedInc', 'AveRooms', 'AveOccup', 'HouseAge']].values\n",
        "y_multi = df['MedHouseVal'].values\n",
        "\n",
        "# Fit the linear regression model\n",
        "reg_multi = LinearRegression()\n",
        "reg_multi.fit(X_multi, y_multi)\n",
        "\n",
        "# Display the coefficients\n",
        "print(f\"Intercept (β0): {reg_multi.intercept_:.2f}\")\n",
        "print(f\"Coefficients (β1, β2, β3, β4): {reg_multi.coef_}\")\n",
        "\n",
        "# Matrix formulation\n",
        "X_multi_b = np.c_[np.ones((X_multi.shape[0], 1)), X_multi]\n",
        "beta_hat_multi = np.linalg.inv(X_multi_b.T.dot(X_multi_b)).dot(X_multi_b.T).dot(y_multi)\n",
        "\n",
        "print(f\"Computed intercept (β0): {beta_hat_multi[0]:.2f}\")\n",
        "print(f\"Computed coefficients (β1, β2, β3, β4): {beta_hat_multi[1:]}\")\n"
      ],
      "metadata": {
        "id": "FEpQj88rugmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming df_sample is the filtered and sampled dataframe from earlier\n",
        "\n",
        "# List of predictors\n",
        "predictors = ['MedInc', 'AveRooms', 'AveOccup', 'HouseAge']\n",
        "\n",
        "# Create scatter plots\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, predictor in enumerate(predictors, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.scatterplot(x=df_sample[predictor], y=df_sample['MedHouseVal'], alpha=0.5)\n",
        "    plt.title(f\"House Prices vs {predictor}\")\n",
        "    plt.xlabel(predictor)\n",
        "    plt.ylabel(\"Median House Value (in $100,000s)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cVc_eHXzvvWE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}